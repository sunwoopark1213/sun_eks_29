# ###############################################################################
# I. VPC Network Architecture: 클러스터 구성을 위한 사전 준비
# ============================================================================================
# 1. 리전 및 가용 영역 정보
# ---------------------------------------------------------------------------------------------------------------------
# - Region: ap-northeast-1 (도쿄)
# - Availability Zones: ap-northeast-1a / ap-northeast-1c / ap-northeast-1d

# ============================================================================================
# 2. VPC와 네트워크 기본정보
# ---------------------------------------------------------------------------------------------------------------------
# Type Availability Zone Subnet ID CIDR 블록 비고
# ---------------------------------------------------------------------------------------------------------------------
# vpc vpc-089fe9578dcc1c00c 10.0.0.0/20 IGW
# ---------------------------------------------------------------------------------------------------------------------
# Public Subnet ap-northeast-1a subnet-0b1805c1e9f180871 10.0.0.0/26 NAT, 외부 LB용
# ap-northeast-1c subnet-0bb8d9b6a060a7b6b 10.0.1.0/26 외부 LB용
# ap-northeast-1d subnet-0bc9e9327311ce319 10.0.2.0/26 외부 LB용
# ---------------------------------------------------------------------------------------------------------------------
# Private Subnet ap-northeast-1a subnet-03d99036d72d4e535 10.0.0.64/26 내부 LB용
# ap-northeast-1c subnet-0e961c601df663df9 10.0.1.64/26 내부 LB용
# ap-northeast-1d subnet-0d9812b3f0d502b24 10.0.2.64/26 내부 LB용

# ============================================================================================
# 3. VPC와 Subnet에 아래와 같이 태그를 추가합니다:
# kubernetes.io/role/elb=1이 지정된 퍼블릭 서브넷은 외부 로드밸런서용 서브넷 대상이 되는 것으로,
# ---------------------------------------------------------------------------------------------------------------------
# 대상 리소스 태그 키 (Key) 태그 값 (Value) 비고
# ---------------------------------------------------------------------------------------------------------------------
# VPC kubernetes.io/cluster/[cluster-name] shared 인프라 식별
# ---------------------------------------------------------------------------------------------------------------------
# Public Subnet kubernetes.io/cluster/[cluster-name] shared 클러스터 소속
# kubernetes.io/role/elb 1 외부 LB용
# ---------------------------------------------------------------------------------------------------------------------
# Private Subnet kubernetes.io/cluster/[cluster-name] shared 클러스터 소속
# kubernetes.io/role/internal-elb 1 내부 LB용

# ============================================================================================
# 4. 보안 그룹 설정
# ---------------------------------------------------------------------------------------------------------------------
# Name Secrets Group ID 인바운드 규칙
# ---------------------------------------------------------------------------------------------------------------------
# csjin-default-sg sg-025ab8cfad0cab78c delete inbound
# csjin-ssh-sg sg-04264d83ba971cc87 SSH(22) User's IP
# csjin-alb-sg sg-0dab199d320638d6a HTTP(80) 0.0.0.0/0
# HTTPS(443) 0.0.0.0/0
# TCP(8000) 0.0.0.0/0
# csjin-cluster-sg sg-0746271ec52f43ed1 TCP(30000 - 32767) csjin-alb-sg
# csjin-mysql-sg sg-082666b0cbf035f8e MySQL(3306) csjin-ssh-sg, csjin-cluster-sg

# ============================================================================================
# 5. Application Load Balancer용 IAM Role 생성
# ---------------------------------------------------------------------------------------------------------------------
# - 역할 이름: eksctl-csjin-cluster-Role1-1A2B2C3D4E5F
# - 정책 연결: AmazonEC2FullAccess

# ###############################################################################
# II. EKS Cluster Creation and Management
# ============================================================================================
# eksctl 클러스터 명령
# ---------------------------------------------------------------------------------------------------------------------
# 단계 실행 도구 명령어 및 설명
# 최초 생성 eksctl create cluster -f cluster.yaml YAML 설계도대로 클러스터와 노드를 처음 구축합니다.
# 설정 변경 eksctl upgrade nodegroup -f cluster.yaml 노드 그룹의 설정(버전, IAM 권한 등)을 수정하여 반영합니다.
# 개수 조정 eksctl scale nodegroup -f cluster.yaml YAML에 정의된 min/max/desired 값으로 노드 대수를 맞춥니다.
# 삭제 eksctl delete cluster -f cluster.yaml 클러스터와 관련 리소스를 모두 삭제합니다.
# ---------------------------------------------------------------------------------------------------------------------


# ###############################################################################
# II. 실행
# ============================================================================================
# 1. EKS 클러스터 및 노드 그룹 생성
# ---------------------------------------------------------------------------------------------------------------------
eksctl create cluster -f create_cluster.yaml

# (필요할 경우)노드 그룹의 노드 수 조정
eksctl scale nodegroup \
--cluster=csjin-cluster \
--name=csjin-cluster-ng \
--nodes=2 \
--nodes-min=1 \
--nodes-max=3

# 현재 리전에 생성된 EKS 클러스터 목록과 상태 확인
eksctl get cluster [--name csjin-cluster]
# 인프라 관점에서의 노드 그룹 상태 및 개수 확인
kubectl get nodes [-o wide]
eksctl get nodegroup --cluster csjin-cluster
# AWS CloudFormation 스택 상태(인프라 구성 완료 여부) 확인
eksctl utils describe-stacks --cluster csjin-cluster > cloudformation-stacks.txt
# 사용중인 Local PC와 클러스터 간의 연결정보를 업데이트
aws eks --region ap-northeast-1 update-kubeconfig --name csjin-cluster
kubectl get nodes -o wide

# ============================================================================================
# 2. 로드밸런서를 자동 생성하기 위한 작업
# ---------------------------------------------------------------------------------------------------------------------
# 1) 역할담당자(신분증) 생성: IAM OIDC 프로바이더 연결 확인
# 실제 로드밸런서 생성을 위해 담당할 역할자의 역할 생성 : 여러번 실행 대비(--override-existing-serviceaccounts)
# IAM Service Account (IRSA: IAM Roles for Service Accounts)를 생성하여 ALB 컨트롤러에 권한 부여합니다.
# IRSA는 쿠버네티스 파드에게 AWS 리소스를 다룰 수 있는 신분증(권한)을 부여하는 것입니다.
# AWS Load Balancer Controller가 ALB를 생성하고 관리할 수 있도록 AmazonEC2FullAccess 정책을 연결한
# IAM 역할자를 kube-system 네임스페이스에 aws-load-balancer-controller 이름으로 생성합니다.
# 이후 로드밸런서를 생성할 때 이 aws-load-balancer-controller 서비스 계정을 사용하게 됩니다.
eksctl create iamserviceaccount \
--cluster=csjin-cluster \
--namespace=kube-system \
--name=aws-load-balancer-controller \
--attach-policy-arn=arn:aws:iam::aws:policy/AmazonEC2FullAccess \
--override-existing-serviceaccounts \
--approve

# 2) Helm 차트로 AWS Load Balancer Controller 설치
# Helm이 설치되어 있지 않다면 먼저 설치합니다.
# Helm 설치: https://helm.sh/docs/intro/install/
# 역할자를 생성하기 위한 AWS EKS 차트 리포지토리 추가
helm repo add eks https://aws.github.io/eks-charts

# 최신 정보로 업데이트
helm repo update

# AWS Load Balancer Controller 설치
helm upgrade --install aws-load-balancer-controller eks/aws-load-balancer-controller \
-n kube-system \
--set clusterName=csjin-cluster \
--set serviceAccount.create=false \
--set serviceAccount.name=aws-load-balancer-controller \
--set region=ap-northeast-1 \
--set vpcId=vpc-089fe9578dcc1c00c

# 참고) 설치 제거 명령
# helm uninstall aws-load-balancer-controller -n kube-system

# 30초 정도 뒤에 설치 확인
kubectl get deployment -n kube-system aws-load-balancer-controller

# ============================================================================================
# 3. 서비스 및 Ingress , Deployment 배포
# ---------------------------------------------------------------------------------------------------------------------
# 배포 실행 명령: NodePort 버전
kubectl apply -f web-deployment-nodeport.yaml

# 배포 실행 명령: ClusterIP 버전
# kubectl apply -f web-deployment-clusterip.yaml

# 상태 확인
kubectl get svc web-project-svc -w
kubectl get ingress web-project-svc

# 로드밸런서 컨트롤러가 ALB를 잘 만들고 있는지 실시간 로그 확인
kubectl logs -n kube-system -l app.kubernetes.io/name=aws-load-balancer-controller -f

# ###############################################################################
# III. 참고 사항
# 네트워크 드라이버를 NodePort로 사용할 경우 : 포트는 30000 ~ 32767 사이에서 자동 할당됩니다.
# --> 이경우 인스턴스에는 반드시 해당 포트를 위 범위로 열어주어야 합니다.
# 네트워크 드라이버를 ClusterIP로 사용할 경우 : 노드 포트가 아닌 클러스터 내부 IP로만 통신합니다.
# --> 이경우 인스턴스에는 서비스들의 정의된 포트들만 열려 있으면 됩니다.
# ###############################################################################